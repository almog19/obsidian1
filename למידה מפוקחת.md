# מבוא
פונקצית מחיר
ה - GRADIENT DECENT
ה - LEARNING GRADES
ווקטורים
מאפיינים SCALING, ENGENEERING.
ריגרסיה פולינולית
ריגרסיה לוגיסטית - פונקצית מחיר, OVERFITTING, UNDERFITTING, 
סוגי רגולריסציה - dropout, ridge, 



פרספטרון

שאלות:
למה MSE הכי משומש?
מה GRADIENT DECENT עושה?
איך אפשר להגיע לנקודת המינימום/מקסימום הכי קיצונית?
מה מתמשים באיזון משתנים?
מה זה חלחול לאחור/קדימה?
מה זה bias ו - variance?

איך רשת ניורונים מצליחה להחליט איזה מאפיינים משפיעים יותר?
איך שכבת hidden יכולה להתמקד לפי דברים שונים?
מה ההבדלים בין וקוטור w ו - b בין הניורונים באותו השכבה?
האיך המודל מתאמן? האם כל ניורון מחפש את הפרמטרים הטובים ביותר? איך החלחול לאחור משפיע על ה GD, אחרי כל EPOCH משתנים הפרמטרים?
מה זה epoch?
אילו סוגי loss יש?
למה קצבות שטוחים גורמים ל GD להיות יותר שטוח?
היפרפרמטרים?


בלמידה מפוקחת, משתמשים באלגוריתם מסויים בשביל ללמוד, האלגוריתם מקבל שתי דברים:
משתנה קלט, מאפיין - x
משתנה פלט, התשובה הנכונה - y
מספר הדוגמאות - m
אחרי האלגוריתם ללמוד, האלגוריתם יפתח פונקציה,מודל - ( f).
המודל ישומש, כך שיקבל קלט חדש ויוצאי חיזוי -( $\hat{y}$ ), 

ה - training set, מכיל את המאפיינים(x), ואת המשתנה הפלט(y).

##### המודל:
המודל משתמש בפרמטרים המשתנים, ומתאים אותם בזמן אימון המודל בשביל לשיפור המודל. 
#### פונקצית מחיר:
פונקצית המחיר משמשת להראות עד כמה המודל מתאים למידע שמאומן לפי הפרמטרים שלו, היא מסומנת באות J.
בכך שהמודל מנסה לבדוק את הערך של הפרמטרים שבהם J שואף כמה שיותר קרוב ל - 0.
לפונקצית המחיר יהיה מספר מימדים כמספר הפרמטרים שהמודל משתמש 

ומאפשר למודל להתאים את הפרמטרים שלו לפי פונקצית המחיר.
###### ה - MSE:
בריגרציה לינארית לרוב משתמשים בחישוב הזה, 
ה - MSE זו שיטה לחישוב פרמטרים מותאמים חדשים לפונקצית המחיר.
פונקצית המחיר מודדת את זה לפי כמות השגיאה: 
$j(w,b) = \frac{1}{2m}\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2$


משתמשים בממוצע השגיאות בריבוע, ממוצע בשביל שהשגיאה לא תמשוך לסכום עוד ועוד, ובריבוע בשביל שלא תיהיה תוצאה שלילית


##### ה - gradient decent:
זה אלגוריתם המשמש לצמצם כל פונקציה.
במהלך האלגוריתם ממשיכים לשנות את הפרמטרים, עד שמצליחים למצוא נקודת מינימום/מקסימום.
	אגוריתם:
מתאימים את המשתנים בהתאם לפונקציה(מעדכנים את הפרמטר p):
$p = p - \alpha  \frac{\partial}{\partial p} \times J(p)$
אלפה ($\alpha$) - learning rate, קובע את גודל "הצעד" שה - gradient decent יבצע. 
נגזרת לפי פרמטר ($\frac{d}{dp} \times J(x)$), משמשת להנחות את ה gradient decent לאיזה כיוון "לצעוד", לפי שיפוע גרף המחיר, כאשר גוזרים את פונקצית המחיר לפי הפרמטר p.
	חשוב לעדכן את כל הפרמטרים באותו הזמן, כך שפונקצית מחיר לא תשתנה בזמן חישוב המפרמטרים המותאמים, אלא רק לאחר חישוב כל המפרמטרים ביחד.
###### איזון מאפיינים(feature scaling):
מאפשר ל - gradient decent לרוץ יותר מהר, משומש כאשר יש מאפיינים שהערך שלהם גדול/קטן מאוד, כך שהשפעה שלהם גם תיהיה גדולה/קטנה. ולכן המשקלים של המאפיינם שלהם צריכים להשתנות בהתאם.
יש מספר דרכים לפתור את הבעיה הזאת:
$x = \frac{x}{max}$ - מהערך הכי נמוך לחלק לכי גבוה עד אחד
ה - mean normalization:
$x = \frac{x-u}{max-min}$ - מורידים ממוצע ומחלקים, התוצאה ממינוס אחד לאחד 
ה - z score normalization:
חישוב החריגה הסטנדרטית -  $\sigma$
$x = \frac{x-\mu}{\sigma}$
#### ה - overfitting
זו בעיה נפוצה כאשר המודל מתאים מאוד ל - training set, ולא בהכרח יחזה טוב דוגמאות חדשות שלא התאמן עליהם, נוצר לרוב כאשר המודל בעל יותר מידי מאפיינים פרטיים.
מראה על כך שיש variance גבוה.
###### פתרונות:
יש מספר פתרונות ל - overfitting:
	איסוף מידע נוסף:
כאשר אוספים יותר מידע, גם ה - training set גדל יותר ומודל יוכל למצוא פונקציה יותר כללית.
	שינוי המאפיינים:
אפשר לשנות את סוגי האפיינים שהמודל מקבל ומתאים משקלים להם.
	רגוליזציה
מאפשר דרך להקטין את ההשפעה של מאפיין מסויים מבלי למחוק אותו לגמרי.

##### ה - underfitting
מקרה מנוגד ל - overfitting, שבו המודל לא מתאים את ה - training set טוב.
מראה על כך שיש bias גבוה
# ריגרציה
תהליך של התאמה של קו(פונקציה) שלפי מידע נוכל לחזות משהו. 
ריגרציה זה למידה של קו מפותל שהכי מתאים למידע בצורה כללי.
מטרת הריגרציה היא לספק ערכים רצופים, נועד בשביל לחזות מספרים.
### ריגרציה לינארית
בריגרציה לינארית, המודל יחזה את הפלט לפי פונקציה(f) לינארית:
פרמטרים:
משקל - w
ה - b??
$f_{w,b}(x) = w\times x + b$
##### פונקצית מחיר
פונקצית המחיר בריגרציה לינארית:
$J(w,b) = \frac{1}{2m}\sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2$
#### ה - gradient decent
פונקצית gradient decent בריגרציה לינארית:
$w = w - \alpha \frac{\partial}{\partial w} \times [\frac{1}{m}\sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})\times x^{(i)}]$
##### ה - normal equation
בריגרציה לינארית יש אלגוריתם נוסף במקום gradient decent לחישוב התאמת הפרמטרים.
מבלי חזרה של חישובים, אבל נחשב לאיטי כאשר מספר מאפיינים גדול.
ספריות של למידת מכונה יכולות להשתמש באלגוריתם הזה.
#### ריגרציה לינארית מרובה
אפשר להשתמש במספר מאפיינים כפלט בשביל לקבל מודל יותר מדוייק, למודל הזה הדוגמאות יהיו מייוצגות כווקטורים, כל ווקטור מכיל את כל המפאיינים של הדוגמא הספיצית.
למודל הזה יהיה כל וקטור למשקלי המודל(w), 
$f_{w,b}(x) = \vec{w}\cdot\vec{x} + b$
	פונקצית מחיר:
$J(\vec{w},b) = \frac{1}{2m}\sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2$
	ה - gradient decent:
ב - gradient decent מחשבים את כל המשקלים מבלי לעדכן, ואז בסוף החישוב מעדכנים את כולם ביחד.
$w_{j} = w_{j} - \alpha \frac{\partial}{\partial w} \times J(\vec{w},b)$
#### ריגרציה פולינום
זה שילוב של ריגרציה לינארית מרובה, והנדוס מאפיינים בשביל לגרום לפונקציה/ שמתעקמת בשביל להתאים יותר למודל.
כאשר מהנדסים מאפניים לרוב בחזקה של מספר מסויים.

# קלסיפיקציה
נועד בשביל לחזות קטגוריות, ממספר מסויים של קבוצות.
### ריגרציה לוגיסטית
ריגרציה לוגיסטית משתמשת בשילוב לינארית, כמו פונקציה ליניארית בעלת ווקטור של משקלים ומאפיינים, ובאותו העת משתמשת בפונקציה היוצר קו סף שקובעת קלסיפיקציה בינארית של 0 או 1.
פונקציות, המשתמשות כפונקציה של z:
$\vec{w} \cdot \vec{x} + b$ - ריגרציה לינארית
$z = \vec{w} \cdot \vec{x} + b$
סיגמואיד - g
$g(z) = \frac{1}{1+e^{-z}}$ 
$g(\vec{w} \cdot \vec{x} + b) = \frac{1}{1+e^{-(\vec{w} \cdot \vec{x} + b)}}$
קביעת גלובולת:
יש קו סף שבו הפונקציה z, שווה ל - 0. בקו הזה הבחירה היא נטרלית.
אפשר גם לגרום לקו הסף להיות פולינום, בעזרת הנדסת מאפיינים ושינוי של חזקות.
##### פונקצית מחיר
פונקצית מחיר לריגרציה לוגיסטית לא משתמשת ב M.S.E, בעקבות זה שהאלגוריתם הזה בשימוש של סיגמואיד יגרום לפונקצית המחיר לא תיהיה קמורה, וה - gradient decent יוכל "להתקע" ולא להגיע לנקודת מינימום המקומית.
פונקצית מחיר משתמשת בפונקצית loss, שמודדת את רמת ההצלחה בדוגמא ספציפית, וסוכמת את כל התוצאות פונקציות ה - loss בשביל ליצור את פונקצית המחיר.
פונקצית loss תכיל את פונקצית המודל,החיזוי ($\hat{y}$), ואת התיוג האמיתי (y). 
פונקצית loss:
בעלת שתי תוצאות המשתנות, כאשר התיוג הוא 0 או 1.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXecSFcOBxqTWaijA-PXX7HcGnmq-vdiu19PuROVThGyMKe6RY1RQWbqGMhQtSyb0BuzC8Nq8DCmAVr_JeUZlK-71aZ9rvtLKItPmHzF_5u6gvlgBxy54U2eR-66ljuevEGcr94b_8EABkGt9jSdygG6G8lM?key=ebgcamQjdTcVzFmU-H4ieg)
פונקצית ה - loss משתמש ב - log, אבל לחישוב, אבל בגלל שהתיוג והחיזוי תמיד יהיו מ - 0 ל - 1, אז לוקחים רק את החלק הזה בפונקציות ה - log.
כאשר y = 1:
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfyEfgtCifDr-GxejTJ54VAssk1FwCagnlwUwvCpDy6HWza8MCgGh8r4SIyf-j93YpNR9f5yLdutSgA70rJbeKCvdSPdJXnkuJ0IDrmnYUy73x22pBRukgiGERR3IxSCvsJ3GMlxpx7pgGZ8WGLeovR4H8Y?key=ebgcamQjdTcVzFmU-H4ieg)
$-\log(f), y = 1$
$f_{w,b}(x^{(i)}) \to 1, L \to0$
$f_{w,b}(x^{(i)})\to_{0},L\to{\infty}$
ה - loss יותר נמוך כאשר $f_{w,b}(x^{(i)})$ חוזה יותר קרוב לתיוג האמיתי(y)
כאשר y = 0:
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXe_Tl7fcP9Y_TwMKWqqKwea7STt_9ewdjBhF1N_v9X08zupUwSfMUbHLQH9gWL7cwCLX9INM0E38qdKyQnCyl8sHKMU5RUX0oKaTZunJZ9xtrUVIl7IT5RDyreRgUjjKUXFDc_vr4DzXApg1amQwdfdsvs?key=ebgcamQjdTcVzFmU-H4ieg)
$-\log(1-f), y = 0$
$f_{w,b}(x^{(i)}) \to 1, L \to{\infty}$
$f_{w,b}(x^{(i)})\to_{0},L\to{0}$
ה - loss יותר גבוה כאשר $f_{w,b}(x^{(i)})$ חוזה יותר רחוק מ תיוג האמיתי(y)
הפונקצית מחיר תראה כך:
$L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)}) = -y^{(i)}\log[f_{\vec{w},b}(\vec{x}^{(i)})] - (1-y^{(i)})\log[1-f_{\vec{w},b}(\vec{x}^{(i)})]$
$J(\vec{w},b) = \frac{1}{m} \sum_{i=1}^{m} L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})$
ה - gradient decent:
אלגוריתם ה - gradient decent נשאר אותו דבר, לפי אותה משוואה. אבל הערך של הפונקציה $f_{\vec{w},b}(\vec{x}^{(i)})$ השתנה. 
# למידה עמוקה
## רשת ניורונים
נירון:
לוקח קלט, מעבד את הקלט ופולט מידע אחר.
ברשת ניורונים הפלט של ניורון אחד משמש כקלט לניורון אחר.
הנוירון משמש אקטיבציה בשביל לעבד את הקלט (a).
#### פונקציות אקטיבציה
פונקציות אלא הן דרך החישוב להסתברות שהקלט יהיה 0 או 1.
משתמשים בפונקציות אקטיבציה בשביל ??? 
פונקציות:
	לינארי:
$g(z) = \vec{w} \cdot \vec{x} + b$
כאשר g(z) = z, משמש בשביל לאפשר למודל לא להשתמש בשום פונקצית אקטיבציה, לרוב משומש כאשר הערך צריך להיות שלילי, ברגרציות לרוב.
	סיגמואיד - g:
$g(z) = \frac{1}{1+e^{-z}}$ 
משמש לרוב רק כאשר המודל צריך לחזות בין 0 או 1
	רילו:
$g(z) = max(0,z)$
יותר קל לגזור לעומת סיגמואיד, לרילו יש קצה אחד שטוח, לסיגמואיד שתי קצבות, הקצבות השטוחים גורם לזה שה - gradient decent יהיה יותר איטי
פועל כאשר z, שלילי g(z) = 0, כאשר z > 0, g(z) = z. 
	סופטמקס:
$z_{j} = \vec{w}_{j} \cdot \vec{x} + b_{j}$
$a_{j} = \frac{e^{z_{j}}}{\sum_{k=1}^{N}e^{z_{k}}}$
משמש לשכבת ה - output, מחשב את הסטיסטיקה לכל תיוג אחרי העיבוד של הרשת כולה.
### שכבות
ברשת ניורונים, יש שכבות של ניורונים, כל שכבה מכילה קבוצה של ניורונים שלוקחים כקלט את אותו מידע/מאפיינים, או חלק מהמידע/מאפיינים.
כל ניורון פולט מאפיין מעובד שנקרא ערך אקטיבציה, מספר ערכי האקטיבציה בשכבה יהיה כמספר הניורונים.

לכל רשת ניורונים יש שכבת input ראשונה, ושכבת output אחרונה. ומכיל שכבות hidden הנמצאות באמצע הרשת. 
שכבת ה - input משתמש ב - $\vec{x}$, שכבת האמצע הראשונה משתמשת ב - $\vec{x}$ ופולטת $\vec{a}$.
היתרון ברשת ניורונים הוא שהרשת יכולה לקבוע איזה מאפיינים משפיעים יותר לקבלת פלט יותר מדוייק, ולהתאים את המשקלים שלו בהתאם. 
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcU8faL4IZCJ0fDOQprmE46OYjvktM0MlKhRrbgWT3ZhBfG0VD8aoOoPuwiusGP0Bxoc_Y6-vQW5IA9Ai3gC9i8IKGQnzniQal9RjJC_CRtyEPxEVDvhrTOM55dlJ_U4VADvGU_lyPFie2N6WSBk-37-Po?key=ebgcamQjdTcVzFmU-H4ieg)
#### חלחול
חלחול מתאר את התהליך של חישוב הפלט מהמודל ושינוי המשקלים להקטנת השגיאה.
- חלחול קדימה:
תהליך של עברת מידע של קלט, לעבד אותו במודל ולקבל את הפלט של המודל.
השלב הבא הוא למדוד עד כמה יש שגיאה על ידי פונקצית המחיר.
- חלחול לאחור:
התהליך של חישוב השיפוע של פונקצית המחיר לפי כל משקל ו - bias במודל, אחר כך מעדכנים את כל הפרמטרים באותו הזמן. 
החישוב משתמש בתיוג של המודל, לחישוב השיפוע של המשקלים בשכבת הפלט.
השגיאה שחושבה מחולחלת אחורה ל - hidden layer, שהשיפוע של המשקלים בשכבה הזאת מחושבים. התהליך נעשה שוב ושוב עד שכל המשקלים וה - bias הותאמו.
#### אימון רשת ניורונית
אין הרשת נעשת על ידי שלושה שלבים:
1) ציון דרך עיבוד הקלט לפלט
נעשה על ידי פירוט המודל(sequential), שכבות המודל מספר הניוטרונים סוג שכבה פונקציות אקטיבציה ועוד...
2) קומפילציה
לקמפל את המודל ולציין את סוג ה - loss שהמודל ישתמש בו. הקומפילציה מספקת גם את פונקצית המחיר.
3) לצמצם את פונקצית המחיר
לנסות לצמצם כמה שיותר על ידי התאמה של הפרמטרים בפונקציה של הרשת הניורונית, נעשה על ידי fit.
האימון נעשה על ידי שימוש בחלחול לאחור, 
##### אופטימציות
יש מספר אלגוריתמים שאמפשרים לאימון מודל יותר מהיר, טוב.
	ה - Adam
אחראי לשינוי גודל ה - learning rate באלגוריתם לצמצום פונקצית המחיר 
וכך הופך את התליך ליותר מהיר.
ב - gradient decent משנה את גודל האלפה($\alpha$), כאשר ב - gradient decent כיוון "הצעד"/הנגזרת לא משנה כיוון, או משנה כיוון כל הזמן אז Adam יגדיל, או יקטין את האלפה.
### ה - autoencoder
סוג של רשת ניורונים שמנסה ללמוד משקלים שמשאירים את הפלט כמה שיותר קרוב לקלט.
ברשת הזו יש שכבות באמצע(hidden layers).
- תהליך encoding
כאשר בשכבה יש פחות מימדים(ניורונים) מהקלט, אז השכבה תדחוס את המידע.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfqAF1FlnEplFTunBBueNtaS1q0rA6pNThiShKmsRN-tN14wmyPGJiOVcnJrT4MiHEnEjFbugPyYXNhfkf4EOTEFaUvpsxNQHoRahCRR3P8zlt2nefYocUIwJOlKTA5JRD6as79Ql7aNjIuzyeCg3bAGvxy?key=ebgcamQjdTcVzFmU-H4ieg)
- תהליך decoding
תהליך של שחזור הקלט משכבת ה - hidden.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdeUgKp2e3dIwOJ6OVBVgJiq9r03qyNbiUwMnPT-2GBbh9I3HOzpfjHv4d_XZ9P21PdGMw8s_U2Yv5feX9i5qSjz4t9ONSgg1dT73BqcQQ5PlEgcOkoHiCx05WNVz-NJ6TTFmQuMEz9FH16nOQlDmHJg2tC?key=ebgcamQjdTcVzFmU-H4ieg)

## ה - CNN
זה דרך נוספת לעיבוד של ניורונים ברשת, להתקדמות ברשת.
מודל CNN מסווג מאוד טוב עצמים שמוצגים, לרוב בתמונות משומש.
יתרונות:
מאפשר לחסור בפרמטרים, בעקבות שימוש חוזר של הפרמטרים שוב ושוב.
תהליך:
המודל מבצע "סריקה" של חלקים מהתמונה בעזרת פילטר.
הפילטר משמש כדרך להדגיש מאפיינים במידע(בתמונות קצבות, צורות).
אחרי תהליך הסריקה נוצרת מטריצת output, מוסיפים לה bias ופונקצית אפליקציה:
ReLU(output matrix + b)
בתהליך ה - convolution גודל המטריצה מקורית מוקטן, ולכנן אפשר להוסיף padding, מידע למטריצה הממקורית(פיקסלים לתמונות) כך שגודל המטריצה שתיווצר תיהיה גדול המטריצה המקורית. 
- קובולוציה של 1X1

מספק דרך להקטין את מספר הגודל של המימד השלישי, 
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcBKAi99_D1uRQVlTQx4R5yNCAkHAMNhsevI57qU90M-lzys8trR1PSTzfpQMUN-e-E9OAgInQlz8RdRMcpNxSHuacqJR4jqE95xwntEhqlC7P8jLkTI7bgdr05Ij1sMyQ4uiKc9uXXr3JAwy6wBC7Toug?key=ebgcamQjdTcVzFmU-H4ieg)
### ה - pooling
מספק דרך לפשט את החישובים מתוצאת ה - convolution, מבלי לאבד הרבה מידע.
**![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXew3SEidZX5e5h7-YuxMIfMuv-rsNclgMwiv0hAzn1RbIyz-NYxHNSPG74y7Q9ccFNRwSRhK_P1kxk2-RzWEAtzRz2g3MmvW6ktlTN09rQwLe0TIHdQQU2s9UYMf1-qyJsbMDWPpIOxv29PWw4VYzbUyc8?key=ebgcamQjdTcVzFmU-H4ieg)**
### רשתות נפוצות
- ה - LeNet 5
2 שכבות convolution
2 שכבות dense
נועד לזיהוי מספרים בתמונות.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdYe_9cDbr1iLhFBbptYIMLVZQXL-hGTHV1RgWEWZGEQSeflXFgOtgtme4Kl34dA9k6PDOC8KkT_KNwiPJMOm4jU-cRBHxxD5n4GrlLm3faY6WNAznT-A88jEKUgomxq4muNb8AeQ_8QRCdGXqMLvunFAw?key=ebgcamQjdTcVzFmU-H4ieg)
- ה -AlexNet
5 שכבות convolution
3 שכבות dense
מאפשר חילוק של תמונה להרבה קטאגוריות של עצמים.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcyuRxHPmUcgXmziX8FJD6c18JZuPEvYRKgquMqW7fsR59rg69cu9ZABlwkyJRcwXlzdoI6pgJqC3Ahd5JumyzC2quHhdL0DeyY_pZcHvG1SSyVjs4B-95YxPDHv5SWJFAcEjXnDgNZ5Or1lvZn1DKm4VN5?key=ebgcamQjdTcVzFmU-H4ieg)
- ה - VGG 16
13 שכבות convolution
3 שכבות dense
זיהוי רב של עצמים בתמונות
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXenEfJfBFmeLgLWPtHZZTo-AbJiiFsmmwAY8NEloq5J8yEBHh04HFWCEq3RB-JkU_akCK8MtkujpWB3YKBkzkH2xOQWIbPS8mxhtfoIDKsfri5uPuCfh4CtgJ-XgjFXCoFGVQLA1OTSKYFvewkNyPYnaw83?key=ebgcamQjdTcVzFmU-H4ieg)
-  ה - ResNets
רשת שבנויה מ - residual block.
כאשר במקום הקלט של שכבה תעבור, את העיבוד הרגיל ותעביר את הפלט שלה ככקלט לשכבה הבאה ולעיבוד חוזר.
מעבירים את הקלט למיקום(שכבה) מתקדם יותר ברשת לפי יישום פונקצית האקטיבציה.
סיבה:
ברשת ניורונים למרות ההיגיון, ככל שיש יותר שכבות כך שגיאת האימון יותר גרוע(בשל מסויים מתחילה לעלות), בעקבות שאלגוריתם האופטימציה(GD) מתקשה להתאמן.
ה - ResNets מאפשר פתרון, כך שיש יותר שכבות שגיאת האימון ממשיכה לרדת.
**לכל Residual block צריך להסתיים עם אותו גודל פלט שהתחיל, אפשר לעשות את זה בעזרת משקל מדומה**
- ה - inception network
משתמש במספר רב של פילטרים/pooling בגדלים שונים, ואוספים את המטריצות שנוצרו ביחד.
**חיסרון** - הרבה מאוד חישובים, שמוכפלים בכמות השכבות של המטריצה שתתקבל משימוש מאותו פילטר/pooling.
ולכן משתמשים בקובולוציה של 1 על 1, בשביל להקטין את החישובים, כך שיווצר מטריצה קטנה יותר, ועל המטריצה שנוצרה מבצאים את גודל הפילטר הרצוי.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc3enaZ4MEXs4xQzaU0ImgUd7xhd2R5E08891RmecRdbPhmPuGjwmbUZZibNXUXCD8amXFgx6rezfZqTmqxcTL-XGMuUsEvWH_zEzJ40QkB6fxtjfTGr7GsVHbNqOmxFRnD1vctH6pXU1eF5twuuq7Jhzw?key=ebgcamQjdTcVzFmU-H4ieg)
לרשתות שמשתמשות ב - inception network מוסיפים "ענפים", כל ענף לוקח hidden layer כלשהי ומנסה להשתמש בה לחזות, לכל ענף ניקח את המידע שעובד עד כה נוסיף לו מספר שכבות dense ובסוף SoftMax.
הדבר הזה מראה שמהשקלים שאומנו עד כל לא כל כך גרועים לחיזוי נכון, ודבר שמספק אפקט של רגולריזציה על הרשת.
- ה - MobileNet
רשת שמאפשר למידת מכונה גם במכשירים כמו טלפונים, בעקבות שכמות החישובים בה נמוך יותר.
הרשת ממשת את זה על ידי חילוק קובולוציה לפי עומק.
המשתמש בשתי שלבים:
1) ה - depthwise convolution
משתמשים בפילטרים בעלי מימד אחד, אבל יהיה מספר פילטרים כספר המימד השלישי בקלט, כך שיווצרו מספר מטריצות כמספר מימדים כמו בקלט.
2) ה - pointwise convolution
נשתמש במטריצות שנוצרו במשלב הקודם, נמשתמש במספר פילטרים שגודלם 1X1 ובעל מימד שלישי כמספר המטריצות נוצרו בשלב הראשון. כך שיווצרו מספר מטריצה שטוחה כמספר הפילטרים.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdlhJ8ecpoPVth3IoicWTK1lq7-0M2I0qroWtCM8__gxfPvQKJmZk3xHKm8_0ouV6wXv_iV1P9dMhQem8Ctfp1zQgFhZPuYvPtv6cwPd20DjeiZ_2HMvNg-_FolpZsKZCcLq-XpSrBKJfVU2JUkKakEJSLv?key=ebgcamQjdTcVzFmU-H4ieg)
לרשת הזו יש גרסה דומה אך שמשתמשת ב - residual block, ובעל שכבה נוספת בתהליך העיבוד של הרחבה.
בשכבת ההרחבה משתמשים במספר של פילתרים של 1X1 על מספר המימדים של הקלט, וכך נוצר מטריצה בעלת מימד שלישי רחב יותר לרוב. ואז בשלב השני(pointwise convolution) נקבץ בחזרה מתהליך ההרחבה.
דבר זה מאפשר לרשת ללמודה פונקציה עשירה יותר בעזרת הרחבת צוור הבקבוק, ועדיין להשתמש בכמות זכרון קטנה יחסית בין שכבות.
## הבחנת עצמים
### איתור עצמים
#### קלסיפיקציה ואיתור
מתאפשר למכונה לספק גם פלט של מיקום העצם שחוזה על ידי הוספת פרמטרים לפלט, פליטה גם של קופסאת גבולות(קופסא המסמנת את מיקום העצם).
כך שלכל פלט יש עוד ארבע פרמטרים:
מיקום מרכז העצם($b_{x}$, $b_{y}$)
אורך הקופסא($b_{h}$)
רוחב הקופסא($b_{w}$)
הפלט יהיה ווקטור, כך שהפרמטר הראשון יהיה ההסתברות שזה עצם, אם זה עצם אז נספק את פרטרים של קוספאת הגבולות, ופרטרים של הקלסיפיקציה(c).
פונקצית מחיר:
תיהיה לרוב בעלת ריגרציה לוגיסטית להסתברות שהעצם קיים, M.S.E להגדרות הקופסא, ופונקצית מחיר אחרת לפלט ה - c, כאשר קיים עצם, כאשר לא קיים עצם התצבע השוואה רק בין התיוג של המכונה לתיוג הנכון.
##### איתור נקודות ציון
המודל יספק פלט של מיקום של נקודות חשובות בתמונה, לשכבת הפלט יוספו עוד שני לכל נקודת ציון, הפרמטרים לפלט($l_{x}$, $l_{y}$),  ואז בתיוג הנכון של המודל יסופק כל המיקומים הנכונים של כל נקודות הציון.
### ה - sliding window
אלגוריתם שמפשר הבחה של עצמים, כאשר יש מודל הזהה האם יש עצם מסויים בתמונה.
1) לוקחים שקופית(חלון) של פיקסלים בתמונה, על החלון נבצע ConvNet(מודל) ונבדול האם זוהה בשקופית עצם.
2) נעביר את השקופית לצד מסויים(כמו פיילטר).
הפעולות האלו מתבצעות שוב ושוב עד סריקה של כל התמונה על השקופית(תמונה חתוכה).
אחרי העברה של השקופית לגבי כל התמונה, נבצע שוב פעם את האלגורית רק עם שקופית יותר גדולה.
- ישום קונבולוציוני ל - sliding window
אפשר **לחסוך את עלות החישוב** על ידי ההמרה של שכבות ה - dense לפילטרים, שכבת ה - dense הראשונה תקטין את הקלט ל 1x1, ויהיה מספר פילטרים כמספר הניורונים בשכבת ה - dense, ואז שכבות ה - dense האחרות יהיו 1x1.![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcByVLtz8McywMNIvfxX8-Ao3lbPwY9qUP95fXnetqUgcBqadWaMe5EovyxbyiDXp4kCW8euY74siM6bB-gEl80alVVT9D76fks4vigpL79JxUt3lp0JM71fu1FAI2nEe9WJLZ7RsPEAn9cirCswBFY3-_v?key=ebgcamQjdTcVzFmU-H4ieg)
פעולה זאת כאשר השקופית היא המטריצה של ה - 14x14x3, מאפשר במקום לרוץ מספר חלחולים שונים על כל המקומות שהשקופית עוברת בתמונה, כל החישוב יאוחדו לאחד(כך שהחישובים החוזרים יבוטלו).
### ה - yolo
מאפשר דיוק של מיקום קופסאת הגבולות, כאשר העצם לא מרובע לגמרי או אף sliding window לא מחסה לגמרי את העצם.
1) חילוק התמונה לרשת של משבצות
2) אלגוריתם של [[#קלסיפיקציה ואיתור]] לכל משבצת של התמונה(מגדיר לאיזה משבצת יש את נקודת המרכז של העצם), כך שעצם לא יאותר בשתי משצבות, אבל קופסאת הגבולות יכולה להיות על שתי משבצות.
	ערכי הפרמטרים של איתור העצם, יהיה מיוחס למשבצת ברשת שהאלגוריתם בוצע                         ($0<b_{x},b{y} < 1$, ו - $b_{h},b_{w}$ יכולים להיות יותר גדולים מ - 1).
**לאלגוריתם הזה יש בעיה של זיהוי עצמים, כאשר יש מספר של עצים באותו משבצת**
#### ה - non max suppuration
מונע מהאלגוריתם לתייג את אותו עצם במספר משבצות שונות, כאשר כל משבצת יכולה להגדיר קופסת גבולות שונה.
האלגוריתם הזה מנקה את קופסאות הגבולות לקופסא אחת.
לוקח את אחוז ה - Pc הכי מוצלח, ואז מתוכך לוקח את הקופסא בעלת ה - IOU הכי מוצלח.
### הערכת איתור המודל
פונקציה הנקראת intersection over union(IOU), מחלקים את השטח המשותף בין, גבולות הקופסה הנכונה לבין גבולות הקופסה שהוגדרה, בשטח הלא משותף של שתי הקוספות. 
#### ה - anchor boxes
כאשר אתה מאפשר לאלגוריתם של קלסיפיקציה ואיתור בכל משבצת להוציא ווקטור של פלט, המכיל את מספר הפרמטרים הרגיל להגדרת קופסה כפול מספר הקופסאות שהמודל יכול לזהות. כך שכל איתור של עצם ישוייך לקופסאת עוגן, לפי ה - IOU הכי מתאים.
**לאלגוריתם יש קושי כאשר יש יותר עצמים מאשר פוקסאות העוגן, או כאשר לשתי עצמים הוגדרו שתי קופסת גבולות הדומות זו לזו.**
לרוב משתמשים ב - k mean אלגוריתם לבחירת פוקסאות העוגן.

## הערכה
משמש בשביל לבדוק האם המודל נמצא במצבשל overfitting, כאשר הוא יכול לחזות רק מה - training set, אבל לא דוגמאות אחרות.
הערכה נעשת על ידי חילוק ה - training set, לעוד קבוצה של קבוצה לבדיקת המודל אחרי האימון(קומפילציה).
הערכה נעשה על ידי חישוב השגיאה של ה - training set לעומת ה - test set.

בשביל לאפשר הערכה האם המודל תקין בזמן האימון, רוב הפעמים מחלקים את ה - training set לעוד קבוצה של cross validation set. ה - Val משמש לבחירת מודל לבדיקה לפיו ומבלי לבצא בדיה ל - test set לכל מודל.
## הבחון
ברוב הפעמיים המודל לא יחזה כפי שרוצים, אפשר לשנות את המודל כך שיוכל לחזות יותר טוב.
ה - bias ו - variance מספקים כמנחה, שיכולים להראות את המצב של המודל ולפי המצב אפשר לטפל במודל.
#### ה - underfitting
כאשר המודל לא מצליח ללמוד לפי דוגמאות האימון, ולכן גם לא יצליח לחזות לפי דוגמאות חדשות.
ה - bias גבוהה.
#### ה - overfitting
כאשר המודל הצליח ללמוד לפי דוגמאות האימון, אבל לא הצליח למצוא הכללה וכאשר מוסיפים לו דוגמאות חדשות לא יכול להחזות כראוי את הדוגמאות.
ה - variance גבוהה

#### ה - bias
מסמן עד כמה המודל עושה הנחות בהתאם לדוגמאות האימון.(לדייק את הניסוח)
פתרונות:
- הוספת מספר המאפיינים(עובד פחות ברשתות)
- הורדת ערך ה - $\lambda$
- הוספת שכבות/ניורונים לרשת
#### ה - variance
מסמן עד כמה החיזוי קשור לדוגמאות האימון, ככל שיותר נמוך יותר טוב
פתרונות:
- הוספת דוגמאות אימון נוספות
- הורדת מספר המאפיינים(עובד פחות ברשתות)
- עלה ערך ה - $\lambda$
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeSqQ6_DJL-cjFH0z6VYTMXKpSwOEqYwUUkNcgZ9-Z6gI89xHCojL8IaorJMBeDJ24OuFBiXaAy2-vnma22B_sQ9JgqvZ8i1RLiyEzLe1i8rkF-rUnkWSCBdN_Gx03bytF68zagdk_qlcPWGpNHkdLepSc?key=ebgcamQjdTcVzFmU-H4ieg)
#### פתרונות
##### רגולריזציה
**רגולרזיציה יכול לגרום לרשת להשפיע לרעה, ולהאט את תהליך האימון בעזרת פישוט פונקצית המודל**
זו דרך שמאפשר להשפיע על האלגוריתם של המודל ולשנות את ה - bias ו - variance בהתאם.
לכל שיטת רגולריזציה יש פרמטר($\lambda$) שמשפיע על כמות שהרגולריזציה תשפיע.
רגולריזציה ליניארית:
כאשר מוסיפים לפונקצית המחיר רמה להשאיר את הפרמטרים של המשקלים קטנים יותר, כאשר שה - bias ישפיע יותר.
$J(\vec{w},b) = \frac{1}{m} \sum_{i=1}^{m} L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})  + \frac{\lambda}{m} \sum_{j=1}^{n}w_{j}^2$
כאשר $\lambda$ גבוהה מאוד, כאשר הערכים של המשקלים יהיו יותר קרובים ל - 0, ואז למודל יושפע יותר מה - bias(underfitting)
כאשר $\lambda$ נמוך מאוד, ערכי המשקלים ישפיעו יותר על המודל, ולמודל יוכל להיות variance גבוהה יותר(overfitting)
 **![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc1UwmVmiJoUFTlxB2B01PPW60chPRrGEXzNqpaTQ1G7Qb7g_iP59uYJZB2CH_htSrLsOZ0oQkX5swWJrmp37e7Wt5R4soTqLvzEHcqZEmqqCsyhMWw5WwTAI2F8TCSSYxly6_wbKvyf7ypRVNpHobMUP4k?key=ebgcamQjdTcVzFmU-H4ieg)**
	 ה - learning curves
 מראה איך השגיאה באלגוריתם מושפעת לפי שינוי מספר הדוגמאות של האימון, איך ה -  $J_{val}$ מושפע ואיך ה - $J_{train}$ מושפע.
 לרוב ככל שיהיו יותר דוגמאות אימון, כאשר $J_{train}$ השגיאה תיהיה יותר גדולה, בגלל שלמודל יהיה יותר קושי להכלייל יותר דוגמאות, ושגיאת ה - $J_{val}$ תיהיה יותר קטנה, בגלל שהמודל ילמד דרך מסויימת להכליל אותו.
		 מקרה של high bias:
 פונקציות השגיאות התקרבו זה לזה, עד שיצרו סוג של אסימפטוטה אופקית כשל - $J_{train}$ יהיה בהפרש גדול מרמת הדיוק הרצוייה. הוספת דוגמאות לא תוכל לשפר את ביצוי המודל, והורדה נוספת של השגאיות בפונקציות.
 ![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeUr4CnHiQCQdHlG_C-spkkScutL2OnbtiHWbZudIvWatm1KdEquUPOmc0HqGHZjCvsnd3SyJImIPLJiPrMI2CBrnBod6x336Kfp0stmcuPWNStwiTD4TtQEo7-FXh-wcYSOPNTBGOFUFguOOxHVVF3z2yg?key=ebgcamQjdTcVzFmU-H4ieg)
		 מקרה של high variance:
רמת השגיאות ב - $J_{train}$ יכולה להיות כל כך נמוכה שזה לא יהיה אפשרי, בזמן שה - $J_{val}$ ישאר גבוהה. במקרה הזה הוספת דוגמאות תוכל לעזור למודל למצוא הכללה בין סוגי הדוגמאות, ולהגיע לרמה שבה גם ה - $J_{val}$ וה - $J_{train}$ יהיו קרובים זה לזה, ורמת השגיאה של שתיהן תיהיה נמוכה.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeAP21LklySYxypmSVBqi-MxWZDYqAJQ2O0Z2KWlXRFGZ3IjQgIzc82gFN3hNyRonmfuv5CQmPuM-_2FXpvWVjq33pupIr2_g-BbL0AwKvOcAoqce5K6A59edy90N1OJ6Kt5ZpTWbqaapWMkoqU9nl2vYHL?key=ebgcamQjdTcVzFmU-H4ieg)
### פיתוח המודל
פתוח במודל מורכב ממעגל שכאשר חוזרים על התהליך שלו מספר פעמיים לבסוף במודל יוכל להתגבר על מספר קשיים כמו overfitting/underfitting ועוד...
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfqS0uo7YTsljIYL6WDahiR5eERj-9ToyxBd_3p8Cdi1rs694pI2VlRf-6Qhujt-UqfTvMe4pMvhZpxqWDLK9chwrWLBfP3Wo2AXGjCqJyJX83pSoQUa7PX4mRrlGMwtgDbufQBwjXFVwOVms6nQjOllV_w?key=ebgcamQjdTcVzFmU-H4ieg)
#### הבחון שגיאה
לראות את תוצאות המודל, ולבדוק איפה הבעיה של המודל בלמידה, לרוב לוקחים את הדוגמאות שלא הצילחו לתייג נכון ומוצאים דברים משותפים ביניהם.
#### הוספת מידע
הוספת מידע יכול להיות לתרום מאוד למודל, כך יוכל להכליל/ללמוד יותר טוב.
לרוב הוספת מידע מהתחום שהמודל לא הצליח ללמוד יכול לעזור לשגיאה של המודל.
ובכללי לבצע אוגמנטציה על דוגמאות אימון המודל בשביל שהמודל יוכל למצוא מאפיינים יותר כללים.
אוגמנטציה:
- שינוי מצב התמונה
על ידי שינוי רנדומלים כמו, מראה, זום, שינוי זווית התמונה, 
- שינוי צבע התמונה
הוספה/הורדה לערכים של ה - RGB.
##### ה - transfer learning
דרך לפתור מודל כאשר אי אפשר להוסיף מודע נוסף,
הדרך משתמשת בלקיחה של מידע ממשימה אחרת.
לוקחים מכל שכבה את המשקלים שחושבו כבר במודל אחר(חוץ מבשכבת פלט) בעל מספר דוגמאות גדול מאוד, ולאמן את המודל מנקודת התחלה של המשקלים האלו. 
אימון הפרמטרים מנקודת ההתחלה של המשקלים של המודל השני נקרא fine tuning.
איך זה עובד:
כאשר שני המודלים בעלי מטרה זהה כמו זיהוי עצמים בתמונה אז שכבות של הניורונים יזהו את אותם דבריים שעוזרים לתייג נכון בשתי המודלים, 
השכבה הראשונה יכולה ללמוד לזהות קצבות, השנייה קצבות, השלישית צורות...
