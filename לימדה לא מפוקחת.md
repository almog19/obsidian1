## אימון המודל
### ה - k-means
איך משתפר הניחוש??
ה - k מייצג מספר טבעי, שמייצג את מספר הקבוצות לחילוק.
האלגוריתם מתאים את המידע כנקודות במרחב, וכך מחלק את המידע לפי נקודות קרובות זה לזו.
תיוג האלגוריתם הוא ללא תיאור אלא רק לפי מספרים כמו קלאסיפיקציה.
נקודת מרכז נקראת clusters centroids.
פעולה:
האלגוריתם מתחיל בניחוש של מיקום חילוק הקבוצות(ניקודות מרכז), ומשפר את הניחוש שלו בכל שלומד יותר.
הוא מתכנס כאשר הניחוש לא משתפר, או כאשר הוא מגיע למספר מקסימלי של ניחושים.
האלגוריתם מצבע שתי פעולות שוב ושוב על כל נקודות המידע בשביל מיקוד נקודות מרכז המחלקות.
- הקצה
האלגוריתם מקצה נקודת מידע לקבוצה לפי מרכז המחלקה הקרוב ביותר.
- חישוב חוזר
מחשב מחדש את כל נקודות האמצע שעודכנו למחלקות לאחרונה.
#### אלגוריתם
אתחול נקודות מרכז במיקום אקראי כ - k פעמיים.
הקצה:
מספר נקודות המידע(m)
ה - L2 norm, המרחב בין שתי נקודות $||x^{(i)} - \mu_k||^2$
חישוב חוזר:
מיקום של החילוק, שבו נקודות המידע הותאמו($c^{(i)}$),
ממוצע נקודות שהוקצו לנקודת המרחב הזאת($\mu_k$),
נקודת המרכז שנקודת מידע $x^{(i)}$ הותאמה($\mu_{c^{(i)}}$)
מחשבים את ממוצע של כל נתוני הווקטורים לכל נקודה שהוצה למחלקה הנתונה.
**כאשר למחלקה יש 0 דוגמאות שהוגדרו לה(הכי קרובות לה), אפשר לאתחל אותה מחדש במיקום אחר, או להוריד את מספר המחלקות ב - 1.**
#### פונקצית מחיר distortion
פונקצית המחיר היא פונקציה של כל ההתאמות של נקודות המידע למחלקות, וכל מיקום של הנקודות מרכז של כל מחלקה.
פונקצית המחיר היא ממוצע של המרחק בין דוגמא($x^{(i)}$) לנקודת מרכז המחלקה($\mu_{c^{(i)}}$) בריבוע, כך לכל הדוגמאות(m).
**ככה שה - k-mean אלגוריתם מנסה למצוא חלוקה של הדוגמאות ומיקום של מרכז המחלקות כך שהמרחק בין שניהם יהיה הכי קטן**
אתחול נקודות המרכז במיקום אלקראי משפיע על התוצאה הסופית של מיקום הנקודות וחילוק הנקודות, בשביל לבחור מיקום הכי מאוזן אפשר להריץ את האלגוריתם מספר פעמים, ולהשוות בין ערך פונקצית המחיר הסופי אחרי כל אלגוריתם.
לדוגמה:![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeYAfr2_eHNgbgiHOM7riZbeqYR_YthoJT7EaKYTjv_OOwtt8MEmEbXgXhfkfxG8z2Ultv8IUMWZE4sL-CRZUXSGIYHKpGuD1pDqXYY5tTUetKR4d165tnE4z21-L2bcI4_Ek2KxbzUK55tW6TgIFx5paHq?key=ebgcamQjdTcVzFmU-H4ieg)
##### בחירת k
- לכל מספר של מחלקות(k), תיהיה תוצאה שונה לפונקצית מחיר, כך שאפשר להשוות בין הפונציות מחיר הסופיות כפרמטר של k. בגלל שרוב הפעמיים ככל שיש יותר מחלקות כך הפונקצית מחיר תיהיה יותר נמוכה, נבחר ב - k שההפרש בין ה - k הקודם הכי גדול.
- לרוב בוחרים את k לפי המטרה של המכונה, בחירה לפי trade off בין מאפיינים שרוצים להפריד, לדוגמה עד כמה אפשר לכנס את התמונה(איכות) שיהיה אפשר להבחין מה יש בה.
### זיהוי אנומליות
אלגוריתם שמקבל מידע ללא תיוג, ומשייך אזהרה לגבי דוגמאות מיוחדות.
יש מספר אלגוריתמים לזיהוי דוגמאות שונות.
- ה - density estimation
כאשר משתמשים במודל של הסתברות לדוגמא, כלומר מה היסתברות של דוגמא(x) להיות מספר מסויים או בטווח לפי כל הדוגמאות.
בשביל לכפות זיהוי אנומליות צריך להשתמש ב - gaussian distribution.
- ה - gaussian distribution
פונקציה שמתאר את ההיסתבור של דוגמא להיות בערך מסויים(p(x)),
ממוצע ערך הדוגמא($\mu$) - $\mu = \frac{1}{m}\sum_{i=1}^{m}x^{(i)}$
סטיית תקן($\sigma$) - $\sigma^2 = \frac{1}{m}\sum_{i=1}^{m}(x^{(i)}-\mu)^2$
ה - variance($\sigma^2$), מודד את ההתפשטות של הערך x סביב הממוצע($\mu$), 
$p(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{\frac{-(x-\mu)}{2\sigma^2}}$
**כאשר מתמשים בדוגמא בעלת מספר מאפיינים כך שיהיה ווקטור של x, ניקח את הסיכוי של כל מאפיין ($p(x_{j})$), כך שלכל סיכוי של מאפיין יש את ממוצע הדוגמה($\mu)$ ואת סטיית התקן($\sigma$) שלה.**
- מערכת זיהוי שונים
ניקח את כל המאפיינים של כל הדוגמאות, נאמן את ממוצע ערך הדוגמא($\mu$) ואת סטיית התקן($\sigma^2$) לכל מאפניין($x_{j}$).
כאשר התקבלה דוגמא חדשה, נחשב את ההסתברות של המאפיינים שלה(p(x)), 
נבדוק האם הסתברות של הדוגמא הזאת קטנה מאוד, כאשר כן אז זאת דוגמה חריגה.
### ה - self-organized map
