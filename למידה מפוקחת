# מבוא
פונקצית מחיר
ה - GRADIENT DECENT
ה - LEARNING GRADES
ווקטורים
מאפיינים SCALING, ENGENEERING.
ריגרסיה פולינולית
ריגרסיה לוגיסטית - פונקצית מחיר, OVERFITTING, UNDERFITTING, 
סוגי רגולריסציה - dropout, ridge, 



פרספטרון

שאלות:
למה MSE הכי משומש?
מה GRADIENT DECENT עושה?
איך אפשר להגיע לנקודת המינימום/מקסימום הכי קיצונית?
מה מתמשים באיזון משתנים?
מה זה חלחול לאחור/קדימה?
מה זה bias ו - variance?

איך רשת ניורונים מצליחה להחליט איזה מאפיינים משפיעים יותר?
איך שכבת hidden יכולה להתמקד לפי דברים שונים?
מה ההבדלים בין וקוטור w ו - b בין הניורונים באותו השכבה?
האיך המודל מתאמן? האם כל ניורון מחפש את הפרמטרים הטובים ביותר? איך החלחול לאחור משפיע על ה GD, אחרי כל EPOC משתנים הפרמטרים?
אילו סוגי loss יש?
למה קצבות שטוחים גורמים ל GD להיות יותר שטוח?


בלמידה מפוקחת, משתמשים באלגוריתם מסויים בשביל ללמוד, האלגוריתם מקבל שתי דברים:
משתנה קלט, מאפיין - x
משתנה פלט, התשובה הנכונה - y
מספר הדוגמאות - m
אחרי האלגוריתם ללמוד, האלגוריתם יפתח פונקציה,מודל - ( f).
המודל ישומש, כך שיקבל קלט חדש ויוצאי חיזוי -( $\hat{y}$ ), 

ה - training set, מכיל את המאפיינים(x), ואת המשתנה הפלט(y).

##### המודל:
המודל משתמש בפרמטרים המשתנים, ומתאים אותם בזמן אימון המודל בשביל לשיפור המודל. 
#### פונקצית מחיר:
פונקצית המחיר משמשת להראות עד כמה המודל מתאים למידע שמאומן לפי הפרמטרים שלו, היא מסומנת באות J.
בכך שהמודל מנסה לבדוק את הערך של הפרמטרים שבהם J שואף כמה שיותר קרוב ל - 0.
לפונקצית המחיר יהיה מספר מימדים כמספר הפרמטרים שהמודל משתמש 

ומאפשר למודל להתאים את הפרמטרים שלו לפי פונקצית המחיר.
###### ה - MSE:
בריגרציה לינארית לרוב משתמשים בחישוב הזה, 
ה - MSE זו שיטה לחישוב פרמטרים מותאמים חדשים לפונקצית המחיר.
פונקצית המחיר מודדת את זה לפי כמות השגיאה: 
$j(w,b) = \frac{1}{2m}\sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2$


משתמשים בממוצע השגיאות בריבוע, ממוצע בשביל שהשגיאה לא תמשוך לסכום עוד ועוד, ובריבוע בשביל שלא תיהיה תוצאה שלילית


##### ה - gradient decent:
זה אלגוריתם המשמש לצמצם כל פונקציה.
במהלך האלגוריתם ממשיכים לשנות את הפרמטרים, עד שמצליחים למצוא נקודת מינימום/מקסימום.
	אגוריתם:
מתאימים את המשתנים בהתאם לפונקציה(מעדכנים את הפרמטר p):
$p = p - \alpha  \frac{\partial}{\partial p} \times J(p)$
אלפה ($\alpha$) - learning rate, קובע את גודל "הצעד" שה - gradient decent יבצע. 
נגזרת לפי פרמטר ($\frac{d}{dp} \times J(x)$), משמשת להנחות את ה gradient decent לאיזה כיוון "לצעוד", לפי שיפוע גרף המחיר, כאשר גוזרים את פונקצית המחיר לפי הפרמטר p.
	חשוב לעדכן את כל הפרמטרים באותו הזמן, כך שפונקצית מחיר לא תשתנה בזמן חישוב המפרמטרים המותאמים, אלא רק לאחר חישוב כל המפרמטרים ביחד.
###### איזון מאפיינים(feature scaling):
מאפשר ל - gradient decent לרוץ יותר מהר, משומש כאשר יש מאפיינים שהערך שלהם גדול/קטן מאוד, כך שהשפעה שלהם גם תיהיה גדולה/קטנה. ולכן המשקלים של המאפיינם שלהם צריכים להשתנות בהתאם.
יש מספר דרכים לפתור את הבעיה הזאת:
$x = \frac{x}{max}$ - מהערך הכי נמוך לחלק לכי גבוה עד אחד
ה - mean normalization:
$x = \frac{x-u}{max-min}$ - מורידים ממוצע ומחלקים, התוצאה ממינוס אחד לאחד 
ה - z score normalization:
חישוב החריגה הסטנדרטית -  $\sigma$
$x = \frac{x-\mu}{\sigma}$
#### ה - overfitting
זו בעיה נפוצה כאשר המודל מתאים מאוד ל - training set, ולא בהכרח יחזה טוב דוגמאות חדשות שלא התאמן עליהם, נוצר לרוב כאשר המודל בעל יותר מידי מאפיינים פרטיים.
מראה על כך שיש variance גבוה.
###### פתרונות:
יש מספר פתרונות ל - overfitting:
	איסוף מידע נוסף:
כאשר אוספים יותר מידע, גם ה - training set גדל יותר ומודל יוכל למצוא פונקציה יותר כללית.
	שינוי המאפיינים:
אפשר לשנות את סוגי האפיינים שהמודל מקבל ומתאים משקלים להם.
	רגוליזציה
מאפשר דרך להקטין את ההשפעה של מאפיין מסויים מבלי למחוק אותו לגמרי.

##### ה - underfitting
מקרה מנוגד ל - overfitting, שבו המודל לא מתאים את ה - training set טוב.
מראה על כך שיש bias גבוה
# ריגרציה
נועד בשביל לחזות מספרים

### ריגרציה לינארית
בריגרציה לינארית, המודל יחזה את הפלט לפי פונקציה(f) לינארית:
פרמטרים:
משקל - w
ה - b??
$f_{w,b}(x) = w\times x + b$
##### פונקצית מחיר
פונקצית המחיר בריגרציה לינארית:
$J(w,b) = \frac{1}{2m}\sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2$
#### ה - gradient decent
פונקצית gradient decent בריגרציה לינארית:
$w = w - \alpha \frac{\partial}{\partial w} \times [\frac{1}{m}\sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})\times x^{(i)}]$
##### ה - normal equation
בריגרציה לינארית יש אלגוריתם נוסף במקום gradient decent לחישוב התאמת הפרמטרים.
מבלי חזרה של חישובים, אבל נחשב לאיטי כאשר מספר מאפיינים גדול.
ספריות של למידת מכונה יכולות להשתמש באלגוריתם הזה.
#### ריגרציה לינארית מרובה
אפשר להשתמש במספר מאפיינים כפלט בשביל לקבל מודל יותר מדוייק, למודל הזה הדוגמאות יהיו מייוצגות כווקטורים, כל ווקטור מכיל את כל המפאיינים של הדוגמא הספיצית.
למודל הזה יהיה כל וקטור למשקלי המודל(w), 
$f_{w,b}(x) = \vec{w}\cdot\vec{x} + b$
	פונקצית מחיר:
$J(\vec{w},b) = \frac{1}{2m}\sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2$
	ה - gradient decent:
ב - gradient decent מחשבים את כל המשקלים מבלי לעדכן, ואז בסוף החישוב מעדכנים את כולם ביחד.
$w_{j} = w_{j} - \alpha \frac{\partial}{\partial w} \times J(\vec{w},b)$
#### ריגרציה פולינום
זה שילוב של ריגרציה לינארית מרובה, והנדוס מאפיינים בשביל לגרום לפונקציה/ שמתעקמת בשביל להתאים יותר למודל.
כאשר מהנדסים מאפניים לרוב בחזקה של מספר מסויים.

# קלסיפיקציה
נועד בשביל לחזות קטגוריות, ממספר מסויים של קבוצות.
### ריגרציה לוגיסטית
ריגרציה לוגיסטית משתמשת בשילוב לינארית, כמו פונקציה ליניארית בעלת ווקטור של משקלים ומאפיינים, ובאותו העת משתמשת בפונקציה היוצר קו סף שקובעת קלסיפיקציה בינארית של 0 או 1.
פונקציות, המשתמשות כפונקציה של z:
$\vec{w} \cdot \vec{x} + b$ - ריגרציה לינארית
$z = \vec{w} \cdot \vec{x} + b$
סיגמואיד - g
$g(z) = \frac{1}{1+e^{-z}}$ 
$g(\vec{w} \cdot \vec{x} + b) = \frac{1}{1+e^{-(\vec{w} \cdot \vec{x} + b)}}$
קביעת גלובולת:
יש קו סף שבו הפונקציה z, שווה ל - 0. בקו הזה הבחירה היא נטרלית.
אפשר גם לגרום לקו הסף להיות פולינום, בעזרת הנדסת מאפיינים ושינוי של חזקות.
##### פונקצית מחיר
פונקצית מחיר לריגרציה לוגיסטית לא משתמשת ב M.S.E, בעקבות זה שהאלגוריתם הזה בשימוש של סיגמואיד יגרום לפונקצית המחיר לא תיהיה קמורה, וה - gradient decent יוכל "להתקע" ולא להגיע לנקודת מינימום המקומית.
פונקצית מחיר משתמשת בפונקצית loss, שמודדת את רמת ההצלחה בדוגמא ספציפית, וסוכמת את כל התוצאות פונקציות ה - loss בשביל ליצור את פונקצית המחיר.
פונקצית loss תכיל את פונקצית המודל,החיזוי ($\hat{y}$), ואת התיוג האמיתי (y). 
פונקצית loss:
בעלת שתי תוצאות המשתנות, כאשר התיוג הוא 0 או 1.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXecSFcOBxqTWaijA-PXX7HcGnmq-vdiu19PuROVThGyMKe6RY1RQWbqGMhQtSyb0BuzC8Nq8DCmAVr_JeUZlK-71aZ9rvtLKItPmHzF_5u6gvlgBxy54U2eR-66ljuevEGcr94b_8EABkGt9jSdygG6G8lM?key=ebgcamQjdTcVzFmU-H4ieg)
פונקצית ה - loss משתמש ב - log, אבל לחישוב, אבל בגלל שהתיוג והחיזוי תמיד יהיו מ - 0 ל - 1, אז לוקחים רק את החלק הזה בפונקציות ה - log.
כאשר y = 1:
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfyEfgtCifDr-GxejTJ54VAssk1FwCagnlwUwvCpDy6HWza8MCgGh8r4SIyf-j93YpNR9f5yLdutSgA70rJbeKCvdSPdJXnkuJ0IDrmnYUy73x22pBRukgiGERR3IxSCvsJ3GMlxpx7pgGZ8WGLeovR4H8Y?key=ebgcamQjdTcVzFmU-H4ieg)
$-\log(f), y = 1$
$f_{w,b}(x^{(i)}) \to 1, L \to0$
$f_{w,b}(x^{(i)})\to_{0},L\to{\infty}$
ה - loss יותר נמוך כאשר $f_{w,b}(x^{(i)})$ חוזה יותר קרוב לתיוג האמיתי(y)
כאשר y = 0:
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXe_Tl7fcP9Y_TwMKWqqKwea7STt_9ewdjBhF1N_v9X08zupUwSfMUbHLQH9gWL7cwCLX9INM0E38qdKyQnCyl8sHKMU5RUX0oKaTZunJZ9xtrUVIl7IT5RDyreRgUjjKUXFDc_vr4DzXApg1amQwdfdsvs?key=ebgcamQjdTcVzFmU-H4ieg)
$-\log(1-f), y = 0$
$f_{w,b}(x^{(i)}) \to 1, L \to{\infty}$
$f_{w,b}(x^{(i)})\to_{0},L\to{0}$
ה - loss יותר גבוה כאשר $f_{w,b}(x^{(i)})$ חוזה יותר רחוק מ תיוג האמיתי(y)
הפונקצית מחיר תראה כך:
$L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)}) = -y^{(i)}\log[f_{\vec{w},b}(\vec{x}^{(i)})] - (1-y^{(i)})\log[1-f_{\vec{w},b}(\vec{x}^{(i)})]$
$J(\vec{w},b) = \frac{1}{m} \sum_{i=1}^{m} L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})$
ה - gradient decent:
אלגוריתם ה - gradient decent נשאר אותו דבר, לפי אותה משוואה. אבל הערך של הפונקציה $f_{\vec{w},b}(\vec{x}^{(i)})$ השתנה. 
# למידה עמוקה
## רשת ניורונים
נירון:
לוקח קלט, מעבד את הקלט ופולט מידע אחר.
ברשת ניורונים הפלט של ניורון אחד משמש כקלט לניורון אחר.
הנוירון משמש אקטיבציה בשביל לעבד את הקלט (a).
#### פונקציות אקטיבציה
פונקציות אלא הן דרך החישוב להסתברות שהקלט יהיה 0 או 1.
משתמשים בפונקציות אקטיבציה בשביל ??? 
פונקציות:
	לינארי:
$g(z) = \vec{w} \cdot \vec{x} + b$
כאשר g(z) = z, משמש בשביל לאפשר למודל לא להשתמש בשום פונקצית אקטיבציה, לרוב משומש כאשר הערך צריך להיות שלילי, ברגרציות לרוב.
	סיגמואיד - g:
$g(z) = \frac{1}{1+e^{-z}}$ 
משמש לרוב רק כאשר המודל צריך לחזות בין 0 או 1
	רילו:
$g(z) = max(0,z)$
יותר קל לגזור לעומת סיגמואיד, לרילו יש קצה אחד שטוח, לסיגמואיד שתי קצבות, הקצבות השטוחים גורם לזה שה - gradient decent יהיה יותר איטי
פועל כאשר z, שלילי g(z) = 0, כאשר z > 0, g(z) = z. 
	סופטמקס:
$z_{j} = \vec{w}_{j} \cdot \vec{x} + b_{j}$
$a_{j} = \frac{e^{z_{j}}}{\sum_{k=1}^{N}e^{z_{k}}}$
משמש לשכבת ה - output, מחשב את הסטיסטיקה לכל תיוג אחרי העיבוד של הרשת כולה.
### שכבות
ברשת ניורונים, יש שכבות של ניורונים, כל שכבה מכילה קבוצה של ניורונים שלוקחים כקלט את אותו מידע/מאפיינים, או חלק מהמידע/מאפיינים.
כל ניורון פולט מאפיין מעובד שנקרא ערך אקטיבציה, מספר ערכי האקטיבציה בשכבה יהיה כמספר הניורונים.

לכל רשת ניורונים יש שכבת input ראשונה, ושכבת output אחרונה. ומכיל שכבות hidden הנמצאות באמצע הרשת. 
שכבת ה - input משתמש ב - $\vec{x}$, שכבת האמצע הראשונה משתמשת ב - $\vec{x}$ ופולטת $\vec{a}$.
היתרון ברשת ניורונים הוא שהרשת יכולה לקבוע איזה מאפיינים משפיעים יותר לקבלת פלט יותר מדוייק, ולהתאים את המשקלים שלו בהתאם. 
#### חלחול
הסבר על חלחול???
	חלחול לאחור:
משתמשים בחלחול לאחור בשביל לחשב נגזרות של פונקצית המחיר.
חישוב הנגזרות:

#### אימון רשת ניורונית
אין הרשת נעשת על ידי שלושה שלבים:
1) ציון דרך עיבוד הקלט לפלט
נעשה על ידי פירוט המודל(sequential), שכבות המודל מספר הניוטרונים סוג שכבה פונקציות אקטיבציה ועוד...
2) קומפילציה
לקמפל את המודל ולציין את סוג ה - loss שהמודל ישתמש בו. הקומפילציה מספקת גם את פונקצית המחיר.
3) לצמצם את פונקצית המחיר
לנסות לצמצם כמה שיותר על ידי התאמה של הפרמטרים בפונקציה של הרשת הניורונית, נעשה על ידי fit.
האימון נעשה על ידי שימוש בחלחול לאחור, 
##### אופטימציות
יש מספר אלגוריתמים שאמפשרים לאימון מודל יותר מהיר, טוב.
	ה - Adam
אחראי לשינוי גודל ה - learning rate באלגוריתם לצמצום פונקצית המחיר 
וכך הופך את התליך ליותר מהיר.
ב - gradient decent משנה את גודל האלפה($\alpha$), כאשר ב - gradient decent כיוון "הצעד"/הנגזרת לא משנה כיוון, או משנה כיוון כל הזמן אז Adam יגדיל, או יקטין את האלפה.
## הערכה
משמש בשביל לבדוק האם המודל נמצא במצבשל overfitting, כאשר הוא יכול לחזות רק מה - training set, אבל לא דוגמאות אחרות.
הערכה נעשת על ידי חילוק ה - training set, לעוד קבוצה של קבוצה לבדיקת המודל אחרי האימון(קומפילציה).
הערכה נעשה על ידי חישוב השגיאה של ה - training set לעומת ה - test set.

בשביל לאפשר הערכה האם המודל תקין בזמן האימון, רוב הפעמים מחלקים את ה - training set לעוד קבוצה של cross validation set. ה - val משמש לבחירת מודל לבדיקה לפיו ומבלי לבצא בדיה ל - test set לכל מודל.
## הבחון
ברוב הפעמיים המודל לא יחזה כפי שרוצים, אפשר לשנות את המודל כך שיוכל לחזות יותר טוב.
ה - bias ו - variance מספקים כמנחה, שיכולים להראות את המצב של המודל ולפי המצב אפשר לטפל במודל.
#### ה - underfitting
כאשר המודל לא מצליח ללמוד לפי דוגמאות האימון, ולכן גם לא יצליח לחזות לפי דוגמאות חדשות.
ה - bias גבוהה.
#### ה - overfitting
כאשר המודל הצליח ללמוד לפי דוגמאות האימון, אבל לא הצליח למצוא הכללה וכאשר מוסיפים לו דוגמאות חדשות לא יכול להחזות כראוי את הדוגמאות.
ה - variance גבוהה

#### ה - bias
פתרונות:
- הוספת מספר המאפיינים(עובד פחות ברשתות)
- הורדת ערך ה - $\lambda$
- הוספת שכבות/ניורונים לרשת
#### ה - variance
פתרונות:
- הוספת דוגמאות אימון נוספות
- הורדת מספר המאפיינים(עובד פחות ברשתות)
- עלה ערך ה - $\lambda$
#### פתרונות
##### רגולריזציה
**רגולרזיציה יכול לגרום לרשת להשפיע לרעה, ולהאט את תהליך האימון**
זו דרך שמאפשר להשפיע על האלגוריתם של המודל ולשנות את ה - bias ו - variance בהתאם.
לכל שיטת רגולריזציה יש פרמטר($\lambda$) שמשפיע על כמות שהרגולריזציה תשפיע.
רגולריזציה ליניארית:
כאשר מוסיפים לפונקצית המחיר רמה להשאיר את הפרמטרים של המשקלים קטנים יותר, כאשר שה - bias ישפיע יותר.
$J(\vec{w},b) = \frac{1}{m} \sum_{i=1}^{m} L(f_{\vec{w},b}(\vec{x}^{(i)}),y^{(i)})  + \frac{\lambda}{m} \sum_{j=1}^{n}w_{j}^2$
כאשר $\lambda$ גבוהה מאוד, כאשר הערכים של המשקלים יהיו יותר קרובים ל - 0, ואז למודל יושפע יותר מה - bias(underfitting)
כאשר $\lambda$ נמוך מאוד, ערכי המשקלים ישפיעו יותר על המודל, ולמודל יוכל להיות variance גבוהה יותר(overfitting)
 **![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc1UwmVmiJoUFTlxB2B01PPW60chPRrGEXzNqpaTQ1G7Qb7g_iP59uYJZB2CH_htSrLsOZ0oQkX5swWJrmp37e7Wt5R4soTqLvzEHcqZEmqqCsyhMWw5WwTAI2F8TCSSYxly6_wbKvyf7ypRVNpHobMUP4k?key=ebgcamQjdTcVzFmU-H4ieg)**
	 ה - learning curves
 מראה איך השגיאה באלגוריתם מושפעת לפי שינוי מספר הדוגמאות של האימון, איך ה -  $J_{val}$ מושפע ואיך ה - $J_{train}$ מושפע.
 לרוב ככל שיהיו יותר דוגמאות אימון, כאשר $J_{train}$ השגיאה תיהיה יותר גדולה, בגלל שלמודל יהיה יותר קושי להכלייל יותר דוגמאות, ושגיאת ה - $J_{val}$ תיהיה יותר קטנה, בגלל שהמודל ילמד דרך מסויימת להכליל אותו.
		 מקרה של high bias:
 פונקציות השגיאות התקרבו זה לזה, עד שיצרו סוג של אסימפטוטה אופקית כשל - $J_{train}$ יהיה בהפרש גדול מרמת הדיוק הרצוייה. הוספת דוגמאות לא תוכל לשפר את ביצוי המודל, והורדה נוספת של השגאיות בפונקציות.
 ![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeUr4CnHiQCQdHlG_C-spkkScutL2OnbtiHWbZudIvWatm1KdEquUPOmc0HqGHZjCvsnd3SyJImIPLJiPrMI2CBrnBod6x336Kfp0stmcuPWNStwiTD4TtQEo7-FXh-wcYSOPNTBGOFUFguOOxHVVF3z2yg?key=ebgcamQjdTcVzFmU-H4ieg)
		 מקרה של high variance:
רמת השגיאות ב - $J_{train}$ יכולה להיות כל כך נמוכה שזה לא יהיה אפשרי, בזמן שה - $J_{val}$ ישאר גבוהה. במקרה הזה הוספת דוגמאות תוכל לעזור למודל למצוא הכללה בין סוגי הדוגמאות, ולהגיע לרמה שבה גם ה - $J_{val}$ וה - $J_{train}$ יהיו קרובים זה לזה, ורמת השגיאה של שתיהן תיהיה נמוכה.
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeAP21LklySYxypmSVBqi-MxWZDYqAJQ2O0Z2KWlXRFGZ3IjQgIzc82gFN3hNyRonmfuv5CQmPuM-_2FXpvWVjq33pupIr2_g-BbL0AwKvOcAoqce5K6A59edy90N1OJ6Kt5ZpTWbqaapWMkoqU9nl2vYHL?key=ebgcamQjdTcVzFmU-H4ieg)
### פיתוח המודל
פתוח במודל מורכב ממעגל שכאשר חוזרים על התהליך שלו מספר פעמיים לבסוף במודל יוכל להתגבר על מספר קשיים כמו overfitting/underfitting ועוד...
![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfqS0uo7YTsljIYL6WDahiR5eERj-9ToyxBd_3p8Cdi1rs694pI2VlRf-6Qhujt-UqfTvMe4pMvhZpxqWDLK9chwrWLBfP3Wo2AXGjCqJyJX83pSoQUa7PX4mRrlGMwtgDbufQBwjXFVwOVms6nQjOllV_w?key=ebgcamQjdTcVzFmU-H4ieg)
#### הבחון שגיאה
לראות את תוצאות המודל, ולבדוק איפה הבעיה של המודל בלמידה, לרוב לוקחים את הדוגמאות שלא הצילחו לתייג נכון ומוצאים דברים משותפים ביניהם.
#### הוספת מידע
הוספת מידע יכול להיות לתרום מאוד למודל, כך יוכל להכליל/ללמוד יותר טוב.
לרוב הוספת מידע מהתחום שהמודל לא הצליח ללמוד יכול לעזור לשגיאה של המודל.
ובכללי לבצע אוגמנטציה על דוגמאות אימון המודל בשביל שהמודל יוכל למצוא מאפיינים יותר כללים.
##### ה - transfer learning
דרך לפתור מודל כאשר אי אפשר להוסיף מודע נוסף,
הדרך משתמשת בלקיחה של מידע ממשימה אחרת.
לוקחים מכל שכבה את המשקלים שחושבו כבר במודל אחר(חוץ מבשכבת פלט) בעל מספר דוגמאות גדול מאוד, ולאמן את המודל מנקודת התחלה של המשקלים האלו. 
אימון הפרמטרים מנקודת ההתחלה של המשקלים של המודל השני נקרא fine tuning.
איך זה עובד:
כאשר שני המודלים בעלי מטרה זהה כמו זיהוי עצמים בתמונה אז שכבות של הניורונים יזהו את אותם דבריים שעוזרים לתייג נכון בשתי המודלים, 
השכבה הראשונה יכולה ללמוד לזהות קצבות, השנייה קצבות, השלישית צורות...
